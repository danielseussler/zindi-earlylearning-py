{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Experimental: Optimisation by Evolutionary Hyperband \n",
    "\n",
    "N. Awad, N. Mallik, and F. Hutter, ‘DEHB: Evolutionary Hyperband for Scalable, Robust and Efficient Hyperparameter Optimization’. arXiv, Oct. 21, 2021. Accessed: Apr. 22, 2023. [Online]. Available: http://arxiv.org/abs/2105.09821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "import lightgbm as lgb\n",
    "import dehb as DEHB\n",
    "import ConfigSpace as CS\n",
    "\n",
    "import time\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    bagging_fraction, Type: UniformFloat, Range: [0.6, 1.0], Default: 1.0\n",
      "    cat_l2, Type: UniformFloat, Range: [5.0, 15.0], Default: 10.0\n",
      "    cat_smooth, Type: UniformFloat, Range: [5.0, 15.0], Default: 10.0\n",
      "    feature_fraction, Type: UniformFloat, Range: [0.6, 1.0], Default: 1.0\n",
      "    num_leaves, Type: UniformInteger, Range: [16, 256], Default: 32\n",
      "\n",
      "Dimensionality of search space: 5\n"
     ]
    }
   ],
   "source": [
    "# define fidelity range\n",
    "min_budget, max_budget = 50, 5000\n",
    "\n",
    "# define config space\n",
    "\n",
    "\n",
    "def create_search_space(seed=0):\n",
    "    \"\"\"Parameter space to be optimized --- contains the hyperparameters\"\"\"\n",
    "    cs = CS.ConfigurationSpace(seed=seed)\n",
    "\n",
    "    cs.add_hyperparameters([\n",
    "        # CS.UniformFloatHyperparameter('learning_rate', lower=1e-4, upper=1.0, default_value=1e-2, log=True),\n",
    "        # CS.UniformFloatHyperparameter('lambda_l1', lower=1e-4, upper=10.0, default_value=1e-4, log=True),\n",
    "        # CS.UniformFloatHyperparameter('lambda_l2', lower=1e-4, upper=10.0, default_value=1e-4, log=True),\n",
    "        # CS.UniformFloatHyperparameter('feature_fraction', lower=0.6, upper=1.0, default_value=1.0, log=False),\n",
    "        # CS.UniformFloatHyperparameter('bagging_fraction', lower=0.6, upper=1.0, default_value=1.0, log=False),\n",
    "        # CS.UniformIntegerHyperparameter('num_leaves', lower=16, upper=256, default_value=32, log=False),\n",
    "        CS.UniformFloatHyperparameter('cat_l2', lower=5.0, upper=15.0, default_value=10.0, log=False),\n",
    "        CS.UniformFloatHyperparameter('cat_smooth', lower=5.0, upper=15.0, default_value=10.0, log=False)\n",
    "    ])\n",
    "\n",
    "    return cs\n",
    "\n",
    "\n",
    "cs = create_search_space(seed=0)\n",
    "print(cs)\n",
    "\n",
    "dimensions = len(cs.get_hyperparameters())\n",
    "print(\"Dimensionality of search space: {}\".format(dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define eval - earlys - valid data sets\n",
    "evalearlys_data_x, valid_data_x, evalearlys_data_y, valid_data_y = train_test_split(\n",
    "    train_data_x,\n",
    "    train_data_y,\n",
    "    train_size=0.9,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "eval_data_x, earlys_data_x, eval_data_y, earlys_data_y = train_test_split(\n",
    "    evalearlys_data_x,\n",
    "    evalearlys_data_y,\n",
    "    train_size=0.9,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "lgb_data_eval = lgb.Dataset(data=eval_data_x, label=eval_data_y)\n",
    "lgb_data_earlys = lgb.Dataset(\n",
    "    data=earlys_data_x, label=earlys_data_y, reference=lgb_data_eval)\n",
    "lgb_data_valid = lgb.Dataset(\n",
    "    data=valid_data_x, label=valid_data_y, reference=lgb_data_eval)\n",
    "lgb_data_test = lgb.Dataset(\n",
    "    data=test_data_x, label=test_data_y, reference=lgb_data_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function interface with DEHB\n",
    "def target_function(config, budget, **kwargs):\n",
    "    # extracting support information\n",
    "    max_budget = kwargs[\"max_budget\"]\n",
    "\n",
    "    if budget is None:\n",
    "        budget = max_budget\n",
    "\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'seed': 0\n",
    "    }\n",
    "\n",
    "    params.update(config.get_dictionary())\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    gbm = lgb.train(\n",
    "        params=params,\n",
    "        num_boost_round=int(budget),\n",
    "        train_set=lgb_data_eval,\n",
    "        valid_sets=[lgb_data_earlys],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)],\n",
    "        keep_training_booster=True\n",
    "    )\n",
    "\n",
    "    cost = time.time() - start\n",
    "\n",
    "    valid_data_pred = gbm.predict(valid_data_x, num_iteration=gbm.best_iteration)\n",
    "    valid_rmse = mean_squared_error(\n",
    "        valid_data_y, valid_data_pred, squared=False)\n",
    "\n",
    "    test_data_pred = gbm.predict(test_data_x, num_iteration=gbm.best_iteration)\n",
    "    test_rmse = mean_squared_error(test_data_y, test_data_pred, squared=False)\n",
    "\n",
    "    best_iteration = gbm.best_iteration\n",
    "    \n",
    "    result = {\n",
    "        \"fitness\": valid_rmse,  \n",
    "        \"cost\": cost,\n",
    "        \"info\": {\n",
    "            \"test_score\": test_rmse,\n",
    "            \"budget\": budget, \n",
    "            \"best_iteration\": best_iteration\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tuning algorithm (hyper-hyperparams are default)\n",
    "dehb = DEHB(\n",
    "    f=target_function,\n",
    "    cs=cs,\n",
    "    dimensions=dimensions,\n",
    "    min_budget=min_budget,\n",
    "    max_budget=max_budget,\n",
    "    eta=3, \n",
    "    strategy='rand1_bin',\n",
    "    mutation_factor=0.5,\n",
    "    crossover_prob=0.5,\n",
    "    n_workers=4,\n",
    "    output_path=\"./temp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-23 07:35:22.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdehb.optimizers.dehb\u001b[0m:\u001b[36mreset\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1m\n",
      "\n",
      "RESET at 04/23/23 07:35:22 W. Europe Summer Time\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 07:35:23,105 - distributed.nanny - WARNING - Restarting worker\n",
      "2023-04-23 07:35:23,124 - distributed.nanny - WARNING - Restarting worker\n",
      "2023-04-23 07:35:23,131 - distributed.nanny - WARNING - Restarting worker\n",
      "2023-04-23 07:35:23,138 - distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "# run tuning algorithm\n",
    "dehb.reset()\n",
    "\n",
    "trajectory, runtime, history = dehb.run(\n",
    "    total_cost=None, \n",
    "    fevals=100,\n",
    "    verbose=False,\n",
    "    max_budget=dehb.max_budget, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 212 212\n",
      "\n",
      "Last evaluated configuration, \n",
      "Configuration(values={\n",
      "  'bagging_fraction': 0.6340546324562695,\n",
      "  'cat_l2': 9.618534421619371,\n",
      "  'cat_smooth': 6.806606215406344,\n",
      "  'feature_fraction': 0.63399434125221,\n",
      "  'lambda_l1': 8.275173171359791,\n",
      "  'lambda_l2': 0.0012553755831805511,\n",
      "  'learning_rate': 0.0001792569563679823,\n",
      "  'num_leaves': 107,\n",
      "})\n",
      "got a score of 10.33612642703613, was evaluated at a budget of 10000.00 and took 481.239 seconds to run.\n",
      "The additional info attached: {'test_score': 10.123112749160718, 'budget': 10000.0, 'best_iteration': 10000}\n",
      "\n",
      "Best evaluated configuration, \n",
      "Configuration(values={\n",
      "  'bagging_fraction': 0.8088284912846216,\n",
      "  'cat_l2': 8.034264947167088,\n",
      "  'cat_smooth': 9.075255369543438,\n",
      "  'feature_fraction': 0.522285555493832,\n",
      "  'lambda_l1': 0.034076843234482956,\n",
      "  'lambda_l2': 0.0077864425839706776,\n",
      "  'learning_rate': 0.018365651651009347,\n",
      "  'num_leaves': 64,\n",
      "})\n",
      "got a score of 9.625861223941522.\n",
      "The additional info attached: {'test_score': 9.568879269018263, 'budget': 3333.333333333333, 'best_iteration': 419}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(trajectory), len(runtime), len(history), end=\"\\n\\n\")\n",
    "\n",
    "# last recorded function evaluation\n",
    "last_eval = history[-1]\n",
    "config, score, cost, budget, _info = last_eval\n",
    "\n",
    "print(\"Last evaluated configuration, \")\n",
    "print(dehb.vector_to_configspace(config), end=\"\")\n",
    "print(\"got a score of {}, was evaluated at a budget of {:.2f} and \"\n",
    "      \"took {:.3f} seconds to run.\".format(score, budget, cost))\n",
    "print(\"The additional info attached: {}\".format(_info), end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Best evaluated configuration, \")\n",
    "print(dehb.vector_to_configspace(dehb.inc_config), end=\"\")\n",
    "print(\"got a score of {}.\".format(dehb.inc_score))\n",
    "print(\"The additional info attached: {}\".format(dehb.inc_info), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
