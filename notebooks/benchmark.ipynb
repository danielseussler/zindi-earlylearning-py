{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import ConfigSpace as CS\n",
    "from dehb import DEHB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import time\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 679)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>child_id</th><th>data_year</th><th>child_date</th><th>child_age</th><th>child_enrolment_date</th><th>child_months_enrolment</th><th>child_grant</th><th>child_years_in_programme</th><th>child_height</th><th>child_observe_attentive</th><th>child_observe_concentrated</th><th>child_observe_diligent</th><th>child_observe_interested</th><th>child_observe_total</th><th>child_gender</th><th>child_dob</th><th>child_zha</th><th>child_stunted</th><th>child_attends</th><th>child_attendance</th><th>child_languages</th><th>child_age_group</th><th>id_mn_best</th><th>prov_best</th><th>id_dc_best</th><th>dc_best</th><th>mn_best</th><th>ward_best</th><th>id_enumerator</th><th>id_facility</th><th>pqa_date</th><th>pqa_class_age</th><th>pqa_class_age_1</th><th>pqa_class_age_2</th><th>pqa_class_age_3</th><th>pqa_class_age_4</th><th>pqa_class_age_5</th><th>&hellip;</th><th>positionother</th><th>positionotherreason</th><th>sef_ind</th><th>language_match</th><th>elp_ind</th><th>gps_ind</th><th>pre_covid</th><th>ses_proxy</th><th>quintile_used</th><th>id_facility_n</th><th>id_ward_n</th><th>id_mn_n</th><th>id_dc_n</th><th>id_prov_n</th><th>language_assessment_w2</th><th>ses_cat</th><th>obs_lighting_1</th><th>obs_lighting_2</th><th>obs_lighting_3</th><th>obs_lighting_4</th><th>obs_lighting_5</th><th>obs_lighting_6</th><th>obs_lighting_8</th><th>obs_cooking_1</th><th>obs_cooking_2</th><th>obs_cooking_3</th><th>obs_cooking_4</th><th>obs_cooking_5</th><th>obs_cooking_6</th><th>obs_heating_1</th><th>obs_heating_2</th><th>obs_heating_3</th><th>obs_heating_4</th><th>obs_heating_5</th><th>obs_heating_6</th><th>obs_heating_7</th><th>target</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>&hellip;</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;ID_SYSJ2FM0D&quot;</td><td>2022.0</td><td>&quot;2022-02-03&quot;</td><td>59.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Sometimes&quot;</td><td>&quot;Sometimes&quot;</td><td>&quot;Sometimes&quot;</td><td>&quot;Sometimes&quot;</td><td>4.0</td><td>&quot;Female&quot;</td><td>&quot;2017-02-06&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;50-59 months&quot;</td><td>&quot;GT421&quot;</td><td>&quot;GAUTENG&quot;</td><td>&quot;DC42&quot;</td><td>&quot;SEDIBENG&quot;</td><td>&quot;EMFULENI&quot;</td><td>39.0</td><td>20005.0</td><td>761.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>&quot;Yes&quot;</td><td>1.0</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Post COVID&quot;</td><td>2.0</td><td>&quot;Yes&quot;</td><td>7.0</td><td>14.0</td><td>107.0</td><td>134.0</td><td>1051.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>51.5</td></tr><tr><td>&quot;ID_J5BTFOZR3&quot;</td><td>2019.0</td><td>null</td><td>60.163933</td><td>null</td><td>null</td><td>null</td><td>&quot;1st year in th…</td><td>103.0</td><td>&quot;Sometimes&quot;</td><td>&quot;Almost never&quot;</td><td>&quot;Sometimes&quot;</td><td>&quot;Often&quot;</td><td>4.0</td><td>&quot;Female&quot;</td><td>null</td><td>-1.356791</td><td>&quot;Normal&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;60-69 months&quot;</td><td>null</td><td>&quot;KWAZULU-NATAL&quot;</td><td>&quot;DC22&quot;</td><td>&quot;UMGUNGUNDLOVU&quot;</td><td>null</td><td>null</td><td>null</td><td>458.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>&quot;Yes&quot;</td><td>1.0</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Pre-COVID&quot;</td><td>4.0</td><td>&quot;Yes&quot;</td><td>24.0</td><td>null</td><td>null</td><td>367.0</td><td>1832.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>55.869999</td></tr><tr><td>&quot;ID_R00SN7AUD&quot;</td><td>2022.0</td><td>&quot;2022-03-11&quot;</td><td>69.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>108.400002</td><td>&quot;Often&quot;</td><td>&quot;Often&quot;</td><td>&quot;Sometimes&quot;</td><td>&quot;Often&quot;</td><td>7.0</td><td>&quot;Male&quot;</td><td>&quot;2016-05-24&quot;</td><td>-1.250863</td><td>&quot;Normal&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;60-69 months&quot;</td><td>&quot;CPT&quot;</td><td>&quot;WESTERN CAPE&quot;</td><td>&quot;CPT&quot;</td><td>&quot;CITY OF CAPE T…</td><td>&quot;CITY OF CAPE T…</td><td>85.0</td><td>20001.0</td><td>925.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>&quot;No&quot;</td><td>1.0</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Post COVID&quot;</td><td>1.0</td><td>&quot;No&quot;</td><td>8.0</td><td>24.0</td><td>1448.0</td><td>1448.0</td><td>3214.0</td><td>null</td><td>&quot;R0-110&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47.52</td></tr><tr><td>&quot;ID_BSSK60PAZ&quot;</td><td>2021.0</td><td>&quot;2021-10-13&quot;</td><td>53.0</td><td>&quot;2020-01-15&quot;</td><td>20.0</td><td>&quot;No&quot;</td><td>&quot;1st year in th…</td><td>98.099998</td><td>&quot;Almost always&quot;</td><td>&quot;Almost always&quot;</td><td>&quot;Sometimes&quot;</td><td>&quot;Often&quot;</td><td>9.0</td><td>&quot;Male&quot;</td><td>&quot;2017-05-08&quot;</td><td>-1.830364</td><td>&quot;Normal&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;50-59 months&quot;</td><td>&quot;WC025&quot;</td><td>&quot;WESTERN CAPE&quot;</td><td>&quot;DC2&quot;</td><td>&quot;CAPE WINELANDS…</td><td>&quot;BREEDE VALLEY&quot;</td><td>18.0</td><td>2689.0</td><td>308.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>&quot;Yes&quot;</td><td>1.0</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Post COVID&quot;</td><td>3.0</td><td>&quot;No&quot;</td><td>4.0</td><td>22.0</td><td>76.0</td><td>629.0</td><td>3214.0</td><td>null</td><td>&quot;R291-750&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>58.599998</td></tr><tr><td>&quot;ID_IZTY6TC4D&quot;</td><td>2021.0</td><td>&quot;2021-10-13&quot;</td><td>57.0</td><td>&quot;2021-10-13&quot;</td><td>0.0</td><td>null</td><td>&quot;2nd year in pr…</td><td>114.0</td><td>&quot;Almost always&quot;</td><td>&quot;Almost always&quot;</td><td>&quot;Almost always&quot;</td><td>&quot;Almost always&quot;</td><td>12.0</td><td>&quot;Female&quot;</td><td>&quot;2016-12-19&quot;</td><td>1.3292638</td><td>&quot;Normal&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;50-59 months&quot;</td><td>&quot;KZN293&quot;</td><td>&quot;KWAZULU-NATAL&quot;</td><td>&quot;DC29&quot;</td><td>&quot;ILEMBE&quot;</td><td>&quot;NDWEDWE&quot;</td><td>10.0</td><td>542.0</td><td>1749.0</td><td>&quot;2021-10-29&quot;</td><td>&quot;4 5&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&hellip;</td><td>null</td><td>null</td><td>&quot;Yes&quot;</td><td>1.0</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Post COVID&quot;</td><td>1.0</td><td>&quot;No&quot;</td><td>1.0</td><td>30.0</td><td>71.0</td><td>315.0</td><td>1832.0</td><td>null</td><td>&quot;R0-110&quot;</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>76.599998</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 679)\n",
       "┌───────────┬─────────┬──────────┬───────────┬───┬────────────┬────────────┬────────────┬──────────┐\n",
       "│ child_id  ┆ data_ye ┆ child_da ┆ child_age ┆ … ┆ obs_heatin ┆ obs_heatin ┆ obs_heatin ┆ target   │\n",
       "│ ---       ┆ ar      ┆ te       ┆ ---       ┆   ┆ g_5        ┆ g_6        ┆ g_7        ┆ ---      │\n",
       "│ str       ┆ ---     ┆ ---      ┆ f64       ┆   ┆ ---        ┆ ---        ┆ ---        ┆ f64      │\n",
       "│           ┆ f64     ┆ str      ┆           ┆   ┆ f64        ┆ f64        ┆ f64        ┆          │\n",
       "╞═══════════╪═════════╪══════════╪═══════════╪═══╪════════════╪════════════╪════════════╪══════════╡\n",
       "│ ID_SYSJ2F ┆ 2022.0  ┆ 2022-02- ┆ 59.0      ┆ … ┆ null       ┆ null       ┆ null       ┆ 51.5     │\n",
       "│ M0D       ┆         ┆ 03       ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "│ ID_J5BTFO ┆ 2019.0  ┆ null     ┆ 60.163933 ┆ … ┆ null       ┆ null       ┆ null       ┆ 55.86999 │\n",
       "│ ZR3       ┆         ┆          ┆           ┆   ┆            ┆            ┆            ┆ 9        │\n",
       "│ ID_R00SN7 ┆ 2022.0  ┆ 2022-03- ┆ 69.0      ┆ … ┆ null       ┆ null       ┆ null       ┆ 47.52    │\n",
       "│ AUD       ┆         ┆ 11       ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "│ ID_BSSK60 ┆ 2021.0  ┆ 2021-10- ┆ 53.0      ┆ … ┆ null       ┆ null       ┆ null       ┆ 58.59999 │\n",
       "│ PAZ       ┆         ┆ 13       ┆           ┆   ┆            ┆            ┆            ┆ 8        │\n",
       "│ ID_IZTY6T ┆ 2021.0  ┆ 2021-10- ┆ 57.0      ┆ … ┆ 0.0        ┆ 0.0        ┆ 0.0        ┆ 76.59999 │\n",
       "│ C4D       ┆         ┆ 13       ┆           ┆   ┆            ┆            ┆            ┆ 8        │\n",
       "└───────────┴─────────┴──────────┴───────────┴───┴────────────┴────────────┴────────────┴──────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = pl.read_csv('../data/Train.csv', ignore_errors=True)\n",
    "sbmssn = pl.read_csv('../data/Test.csv', ignore_errors=True)\n",
    "\n",
    "dataset.head(n=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Some basic data cleaning and feature pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns\n",
    "deselect_col = [\n",
    "    'child_id',\n",
    "    'obs_materials', 'obs_handwashing', 'obs_area', 'obs_toilet',\n",
    "    'obs_equipment', 'obs_safety', 'obs_hazard', 'pqa_class_age',\n",
    "    'pra_groupings', 'pra_plans', 'obs_access_disability', 'pra_cohort',\n",
    "    'pra_plan_4yrs', 'pra_plan_5yrs', 'pra_plan_4yrsother', 'pra_plan_5yrsother',\n",
    "    'pra_qualification', 'pra_ncf_trainer', 'pra_training', 'pri_language',\n",
    "    'pri_languageother', 'pri_meal', 'pri_money', 'pri_moneyother', 'pri_funding_salary', 'pri_expenseother',\n",
    "    'pri_clinic_travel', 'pri_covid_awareness', 'pri_covid_precautions',\n",
    "    'pri_food_type', 'pri_records', 'pri_support_provider', 'pri_support_providerother',\n",
    "    'pri_fees_exceptions_other', 'pri_staff_changes_reasonsother',\n",
    "    'pri_email_network_forum', 'pri_dsd_unregistered_other', 'pri_dsd_conditional_other',\n",
    "    'pri_reason_register_year', 'pri_facilitiesother', 'pri_landother', 'pri_fundingother',\n",
    "    'pri_qualification', 'hle_ecd_other', 'obs_water_running_none', 'obs_waterother'\n",
    "]\n",
    "\n",
    "dataset = dataset.select(pl.all().exclude(deselect_col))\n",
    "sbmssn = sbmssn.select(pl.all().exclude(list(set(deselect_col) - set(['child_id']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date columns we are going to recode\n",
    "date_col = ['child_date', 'child_enrolment_date', 'child_dob', 'pqa_date', 'pra_date', 'pri_date', 'obs_date']\n",
    "\n",
    "for cn in date_col: \n",
    "    dataset = dataset.with_columns(pl.col(cn).str.strptime(pl.Date, '%Y-%m-%d'))\n",
    "    sbmssn = sbmssn.with_columns(pl.col(cn).str.strptime(pl.Date, '%Y-%m-%d'))\n",
    "\n",
    "for cn in date_col: \n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col(cn).dt.year().alias(cn + '_year').cast(pl.Utf8).cast(pl.Categorical), \n",
    "        pl.col(cn).dt.month().alias(cn + '_month').cast(pl.Utf8).cast(pl.Categorical), \n",
    "        pl.col(cn).dt.quarter().alias(cn + '_quarter').cast(pl.Utf8).cast(pl.Categorical),\n",
    "        pl.col(cn).dt.week().alias(cn + '_week').cast(pl.Utf8).cast(pl.Categorical), \n",
    "        pl.col(cn).cast(pl.Int32)\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col(cn).dt.year().alias(cn + '_year').cast(pl.Utf8).cast(pl.Categorical), \n",
    "        pl.col(cn).dt.month().alias(cn + '_month').cast(pl.Utf8).cast(pl.Categorical), \n",
    "        pl.col(cn).dt.quarter().alias(cn + '_quarter').cast(pl.Utf8).cast(pl.Categorical),\n",
    "        pl.col(cn).dt.week().alias(cn + '_week').cast(pl.Utf8).cast(pl.Categorical), \n",
    "        pl.col(cn).cast(pl.Int32)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this to categorical\n",
    "dataset = dataset.with_columns([\n",
    "    pl.col('language_match').map_dict({0: 'No', 1: 'Yes'}, default=None).cast(pl.Categorical)\n",
    "])\n",
    "\n",
    "sbmssn = sbmssn.with_columns([\n",
    "    pl.col('language_match').map_dict({0: 'No', 1: 'Yes'}, default=None).cast(pl.Categorical)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['isiZulu', 'English + isiXhosa +', None, 'Sesotho', 'Afrikaans + Setswana +', 'English + Xitsonga +', 'English + isiNdebele +', 'isiZulu + isiXhosa +', 'English', 'isiXhosa + Xitsonga +', 'English + isiZulu + isiXhosa', 'English + Setswana +', 'English + isiZulu +', 'Sesotho se Leboa (Sepedi)', 'Afrikaans', 'isiXhosa', 'Tshivenda', 'English + Afrikaans +', 'Setswana', 'English + Sesotho se Leboa (Sepedi) +']\n"
     ]
    }
   ],
   "source": [
    "print(dataset['child_languages'].unique().to_list(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract child languages here\n",
    "child_langs = ['Afrikaans', 'English', 'isiNdebele', 'isiXhosa',\n",
    "               'isiZulu', 'Xitsonga', 'Setswana', 'Sesotho', 'Sepedi']\n",
    "\n",
    "for ln in child_langs:\n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col('child_languages').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'child_languages_{ln}')\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col('child_languages').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'child_languages_{ln}')\n",
    "    ])\n",
    "\n",
    "dataset = dataset.drop('child_languages')\n",
    "sbmssn = sbmssn.drop('child_languages')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# FIXME count languages a child speaks\n",
    "dataset = dataset.with_columns([\n",
    "    pl.sum(\n",
    "        pl.col('^child_languages.*$').\n",
    "        cast(pl.Utf8).\n",
    "        map_dict({'No': 0, 'Yes': 1}, default=None, return_dtype=pl.Int64)\n",
    "    ).alias(\"asbdkjasf\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['isiZulu', 'English + Afrikaans + isiXhosa', 'Afrikaans', 'English + isiZulu +', 'Afrikaans + isiZulu +', 'Sesotho', None, 'English + isiXhosa +', 'English', 'Setswana', 'isiXhosa', 'English + Afrikaans +']\n"
     ]
    }
   ],
   "source": [
    "print(dataset['pri_languages'].unique().to_list(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pri_languages here\n",
    "pri_langs = ['Afrikaans', 'English', 'isiXhosa', 'isiZulu', 'Setswana', 'Sesotho']\n",
    "\n",
    "for ln in pri_langs:\n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col('pri_languages').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_languages_{ln}')\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col('pri_languages').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_languages_{ln}')\n",
    "    ])\n",
    "\n",
    "dataset = dataset.drop('pri_languages')\n",
    "sbmssn = sbmssn.drop('pri_languages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the gps column and add polar coordinates\n",
    "dataset = dataset.with_columns(\n",
    "    pl.col('gps').str.split(' ').\\\n",
    "    arr.to_struct(n_field_strategy='max_width').\\\n",
    "    struct.rename_fields(['gps_lat', 'gps_lon'])).\\\n",
    "    unnest('gps')\n",
    "\n",
    "sbmssn = sbmssn.with_columns(\n",
    "    pl.col('gps').str.split(' ').\\\n",
    "    arr.to_struct(n_field_strategy='max_width').\\\n",
    "    struct.rename_fields(['gps_lat', 'gps_lon'])).\\\n",
    "    unnest('gps')\n",
    "\n",
    "# cast to numeric\n",
    "for cn in ['gps_lat', 'gps_lon']:\n",
    "    dataset = dataset.with_columns(pl.col(cn).cast(pl.Float64))\n",
    "    sbmssn = sbmssn.with_columns(pl.col(cn).cast(pl.Float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerics I process as categories\n",
    "numcat_columns = ['id_ward', 'id_enumerator', 'id_facility', 'id_team']\n",
    "\n",
    "for cn in numcat_columns: \n",
    "    dataset = dataset.with_columns(pl.col(cn).cast(pl.Int64).cast(pl.Utf8).cast(pl.Categorical))\n",
    "    sbmssn = sbmssn.with_columns(pl.col(cn).cast(pl.Int64).cast(pl.Utf8).cast(pl.Categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace values with NA's in train.data\n",
    "dataset = dataset.with_columns([\n",
    "    pl.when(pl.col(pl.Utf8).str.contains('Do Not Know|Missing|Don\\'t know|Refuse|DON\\'T KNOW|DON\\'T KNOW.|DON\\'T KNOW THE REASON FOR CONDITIONAL'))\n",
    "    .then(None)\n",
    "    .otherwise(pl.col(pl.Utf8))\n",
    "    .keep_name()\n",
    "])\n",
    "\n",
    "sbmssn = sbmssn.with_columns([\n",
    "    pl.when(pl.col(pl.Utf8).str.contains('Do Not Know|Missing|Don\\'t know|Refuse|DON\\'T KNOW|DON\\'T KNOW.|DON\\'T KNOW THE REASON FOR CONDITIONAL'))\n",
    "    .then(None)\n",
    "    .otherwise(pl.col(pl.Utf8))\n",
    "    .keep_name()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column pri_network_type has different data types between the two data frames.\n",
      "Column pri_staff_changes_reasons has different data types between the two data frames.\n",
      "Column pri_food_donor has different data types between the two data frames.\n"
     ]
    }
   ],
   "source": [
    "# check where dataset and sbmssn diasgree on data types\n",
    "for cn in dataset.select(pl.exclude('target')).columns:\n",
    "    if dataset[cn].dtype != sbmssn[cn].dtype:\n",
    "        print(f'Column {cn} has different data types between the two data frames.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix those columns\n",
    "for answer in [1, 2, 3, 97]:\n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col('pri_network_type').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_network_type_{answer}')\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col('pri_network_type').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_network_type_{answer}')\n",
    "    ])\n",
    "\n",
    "for answer in [1, 2, 3, 4, 5, 6, 97]:\n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col('pri_staff_changes_reasons').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_staff_changes_reasons_{answer}')\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col('pri_staff_changes_reasons').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_staff_changes_reasons_{answer}')\n",
    "    ])\n",
    "\n",
    "for answer in [1, 2, 3, 4, 97]:\n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col('pri_food_donor').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_food_donor_{answer}')\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col('pri_food_donor').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_food_donor_{answer}')\n",
    "    ])\n",
    "\n",
    "# drop the splitted columns\n",
    "dataset = dataset.drop(\n",
    "    ['pri_network_type', 'pri_staff_changes_reasons', 'pri_food_donor'])\n",
    "sbmssn = sbmssn.drop(\n",
    "    ['pri_network_type', 'pri_staff_changes_reasons', 'pri_food_donor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical encoding of some other survey responses\n",
    "for answer in [1, 2, 3, 4, 5, 97]:\n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col('health').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'health_{answer}')\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col('health').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'health_{answer}')\n",
    "    ])\n",
    "\n",
    "# drop the splitted columns\n",
    "dataset = dataset.drop('health')\n",
    "sbmssn = sbmssn.drop('health')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other strings to categories\n",
    "for cn in dataset.select(pl.col(pl.Utf8)).columns: \n",
    "    dataset = dataset.with_columns(pl.col(cn).cast(pl.Categorical))\n",
    "    sbmssn = sbmssn.with_columns(pl.col(cn).cast(pl.Categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training - test split\n",
    "train_data_x, test_data_x, train_data_y, test_data_y = train_test_split(\n",
    "    dataset.drop(['target']).to_pandas(),\n",
    "    dataset.get_column('target').to_pandas(),\n",
    "    train_size=0.9,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# training is splitted for tuning again\n",
    "eval_data_x, valid_data_x, eval_data_y, valid_data_y = train_test_split(\n",
    "    train_data_x,\n",
    "    train_data_y,\n",
    "    train_size=0.8,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Strategy: Gradient Boosted Trees, specifically 'LightGBM'.\n",
    "\n",
    "G. Ke et al., ‘LightGBM: A Highly Efficient Gradient Boosting Decision Tree’, in Advances in Neural Information Processing Systems, Curran Associates, Inc., 2017. [Online]. Available: https://proceedings.neurips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Hyper-parameter tuning with classic Bayesian Optimisation (TPE Sampler)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# optuna hyper-parameter optimization with TPE sampler\n",
    "lgb_data_eval = lgb.Dataset(data=eval_data_x, label=eval_data_y)\n",
    "lgb_data_valid = lgb.Dataset(data=valid_data_x, label=valid_data_y, reference=lgb_data_eval)\n",
    "lgb_data_test = lgb.Dataset(data=test_data_x, label=test_data_y, reference=lgb_data_eval)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.01,\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-4, 100.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-4, 100.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 16, 256, log=True),\n",
    "        # 'feature_fraction': trial.suggest_uniform('feature_fraction', 0.6, 1.0),\n",
    "        # 'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.6, 1.0),\n",
    "        'cat_l2': trial.suggest_uniform('cat_l2', 5, 15),\n",
    "        'cat_smooth': trial.suggest_uniform('cat_smooth', 5, 15),\n",
    "        'verbosity': -1,\n",
    "        'seed': 0\n",
    "    }\n",
    "\n",
    "    # FIXME: should I use here separate validation sets for early stopping and generalization estimate?\n",
    "    gbm = lgb.train(\n",
    "        params=params,\n",
    "        num_boost_round=10000,\n",
    "        train_set=lgb_data_eval,\n",
    "        valid_sets=[lgb_data_valid],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
    "    )\n",
    "\n",
    "    valid_data_pred = gbm.predict(data=valid_data_x, num_iteration=gbm.best_iteration)\n",
    "    rmse = mean_squared_error(valid_data_y, valid_data_pred, squared=False)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "study_bo = optuna.create_study(\n",
    "    sampler=optuna.samplers.TPESampler(seed=0),\n",
    "    direction='minimize'\n",
    ")\n",
    "study_bo.optimize(objective, n_trials=200, n_jobs=4, show_progress_bar=True)\n",
    "\n",
    "print('Number of finished trials:', len(study_bo.trials))\n",
    "print('Best trial:', study_bo.best_trial.params)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = optuna.visualization.plot_optimization_history(study_bo)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = optuna.visualization.plot_intermediate_values(study_hb)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = optuna.visualization.plot_contour(study_hb)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit model on complete training dataset and check prediction error\n",
    "# FIXME"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Hyper-parameter tuning with Hyperband informed by Hyperband.\n",
    "\n",
    "L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, and A. Talwalkar, ‘Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization’. arXiv, Jun. 18, 2018. Accessed: Apr. 22, 2023. [Online]. Available: http://arxiv.org/abs/1603.06560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of brackets 5\n"
     ]
    }
   ],
   "source": [
    "R = 5000/50\n",
    "num_brackets = math.floor(math.log(R, 3)) + 1\n",
    "print('Number of brackets', num_brackets)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# optuna hyper-parameter optimization with hyperband\n",
    "num_boost_round = 5000\n",
    "\n",
    "lgb_data_eval = lgb.Dataset(\n",
    "    data=eval_data_x, label=eval_data_y, free_raw_data=False)\n",
    "lgb_data_valid = lgb.Dataset(\n",
    "    data=valid_data_x, label=valid_data_y, reference=lgb_data_eval, free_raw_data=False)\n",
    "lgb_data_test = lgb.Dataset(\n",
    "    data=test_data_x, label=test_data_y, reference=lgb_data_eval)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.01,\n",
    "        # 'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-4, 100.0),\n",
    "        # 'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-4, 100.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 16, 512, log=True),\n",
    "        # 'feature_fraction': trial.suggest_uniform('feature_fraction', 0.6, 1.0),\n",
    "        # 'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.6, 1.0),\n",
    "        'cat_l2': trial.suggest_uniform('cat_l2', 5, 15),\n",
    "        'cat_smooth': trial.suggest_uniform('cat_smooth', 5, 15),\n",
    "        'verbosity': -1,\n",
    "        'seed': 0\n",
    "    }\n",
    "\n",
    "    # init model and pruning mechanism\n",
    "    gbm = lgb.train(\n",
    "        params=params,\n",
    "        num_boost_round=50,\n",
    "        train_set=lgb_data_eval,\n",
    "        valid_sets=[lgb_data_valid],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)],\n",
    "        keep_training_booster=True\n",
    "    )\n",
    "\n",
    "    for step in range(num_boost_round):\n",
    "        gbm = lgb.train(\n",
    "            params=params,\n",
    "            num_boost_round=num_boost_round,\n",
    "            train_set=lgb_data_eval,\n",
    "            valid_sets=[lgb_data_valid],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)],\n",
    "            keep_training_booster=True,\n",
    "            init_model=gbm\n",
    "        )\n",
    "\n",
    "        intermediate_pred = gbm.predict(\n",
    "            data=valid_data_x, num_iteration=gbm.best_iteration)\n",
    "        intermediate_rmse = mean_squared_error(\n",
    "            valid_data_y, intermediate_pred, squared=False)\n",
    "        \n",
    "        trial.report(intermediate_rmse, step)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    valid_data_pred = gbm.predict(\n",
    "        data=valid_data_x, num_iteration=gbm.best_iteration)\n",
    "    rmse = mean_squared_error(valid_data_y, valid_data_pred, squared=False)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "pruner = optuna.pruners.HyperbandPruner(\n",
    "    min_resource=50, max_resource=num_boost_round, reduction_factor=3)\n",
    "\n",
    "study_hb = optuna.create_study(\n",
    "    sampler=sampler, pruner=pruner, direction='minimize')\n",
    "study_hb.optimize(objective, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "print('Number of finished trials:', len(study_hb.trials))\n",
    "print('Best trial:', study_hb.best_trial.params)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = optuna.visualization.plot_optimization_history(study_hb)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = optuna.visualization.plot_intermediate_values(study_hb)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = optuna.visualization.plot_contour(study_hb)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Experimental: Optimisation by Evolutionary Hyperband \n",
    "\n",
    "N. Awad, N. Mallik, and F. Hutter, ‘DEHB: Evolutionary Hyperband for Scalable, Robust and Efficient Hyperparameter Optimization’. arXiv, Oct. 21, 2021. Accessed: Apr. 22, 2023. [Online]. Available: http://arxiv.org/abs/2105.09821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    cat_l2, Type: UniformFloat, Range: [5.0, 15.0], Default: 10.0\n",
      "    cat_smooth, Type: UniformFloat, Range: [5.0, 15.0], Default: 10.0\n",
      "    lambda_l1, Type: UniformFloat, Range: [0.0001, 10.0], Default: 0.0001, on log-scale\n",
      "    lambda_l2, Type: UniformFloat, Range: [0.0001, 10.0], Default: 0.0001, on log-scale\n",
      "    num_leaves, Type: UniformInteger, Range: [16, 256], Default: 32, on log-scale\n",
      "\n",
      "Dimensionality of search space: 5\n"
     ]
    }
   ],
   "source": [
    "# define fidelity range\n",
    "min_budget, max_budget = 50, 5000\n",
    "\n",
    "# define config space\n",
    "def create_search_space(seed=0):\n",
    "    \"\"\"Parameter space to be optimized --- contains the hyperparameters\"\"\"\n",
    "    cs = CS.ConfigurationSpace(seed=seed)\n",
    "\n",
    "    cs.add_hyperparameters([\n",
    "        CS.UniformFloatHyperparameter('lambda_l1', lower=1e-4, upper=10.0, default_value=1e-4, log=True),\n",
    "        CS.UniformFloatHyperparameter('lambda_l2', lower=1e-4, upper=10.0, default_value=1e-4, log=True),\n",
    "        CS.UniformIntegerHyperparameter('num_leaves', lower=16, upper=256, default_value=32, log=True),\n",
    "        CS.UniformFloatHyperparameter('cat_l2', lower=5.0, upper=15.0, default_value=10.0, log=False),\n",
    "        CS.UniformFloatHyperparameter('cat_smooth', lower=5.0, upper=15.0, default_value=10.0, log=False),\n",
    "        # 'feature_fraction': trial.suggest_uniform('feature_fraction', 0.6, 1.0),\n",
    "        # 'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.6, 1.0),\n",
    "    ])\n",
    "\n",
    "    return cs\n",
    "\n",
    "cs = create_search_space(seed=0)\n",
    "print(cs)\n",
    "\n",
    "dimensions = len(cs.get_hyperparameters())\n",
    "print(\"Dimensionality of search space: {}\".format(dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function interface with DEHB\n",
    "def target_function(config, budget, **kwargs):\n",
    "    # extracting support information\n",
    "    max_budget = kwargs[\"max_budget\"]\n",
    "\n",
    "    if budget is None:\n",
    "        budget = max_budget\n",
    "\n",
    "    lgb_data_eval = lgb.Dataset(data=eval_data_x, label=eval_data_y)\n",
    "    lgb_data_valid = lgb.Dataset(\n",
    "        data=valid_data_x, label=valid_data_y, reference=lgb_data_eval)\n",
    "    lgb_data_test = lgb.Dataset(\n",
    "        data=test_data_x, label=test_data_y, reference=lgb_data_eval)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.01,\n",
    "        'verbosity': -1,\n",
    "        'seed': 0\n",
    "    }\n",
    "\n",
    "    params.update(config.get_dictionary())\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    gbm = lgb.train(\n",
    "        params=params,\n",
    "        num_boost_round=int(budget),\n",
    "        train_set=lgb_data_eval,\n",
    "        # valid_sets=[lgb_data_valid],\n",
    "        # callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)],\n",
    "        # keep_training_booster=True\n",
    "    )\n",
    "\n",
    "    cost = time.time() - start\n",
    "\n",
    "    valid_data_pred = gbm.predict(valid_data_x)\n",
    "    valid_rmse = mean_squared_error(\n",
    "        valid_data_y, valid_data_pred, squared=False)\n",
    "\n",
    "    test_data_pred = gbm.predict(test_data_x)\n",
    "    test_rmse = mean_squared_error(test_data_y, test_data_pred, squared=False)\n",
    "\n",
    "    result = {\n",
    "        \"fitness\": valid_rmse,  # DE/DEHB minimizes\n",
    "        \"cost\": cost,\n",
    "        \"info\": {\n",
    "            \"test_score\": test_rmse,\n",
    "            \"budget\": budget\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tuning algorithm (hyper-hyperparams are default)\n",
    "dehb = DEHB(\n",
    "    f=target_function,\n",
    "    cs=cs,\n",
    "    dimensions=dimensions,\n",
    "    min_budget=min_budget,\n",
    "    max_budget=max_budget,\n",
    "    eta=3, \n",
    "    strategy='rand1_bin',\n",
    "    mutation_factor=0.5,\n",
    "    crossover_prob=0.5,\n",
    "    n_workers=4,\n",
    "    output_path=\"./temp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tuning algorithm\n",
    "dehb.reset()\n",
    "\n",
    "trajectory, runtime, history = dehb.run(\n",
    "    total_cost=60*30, \n",
    "    verbose=False,\n",
    "    save_intermediate=False,\n",
    "    max_budget=dehb.max_budget\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trajectory), len(runtime), len(history), end=\"\\n\\n\")\n",
    "\n",
    "# last recorded function evaluation\n",
    "last_eval = history[-1]\n",
    "config, score, cost, budget, _info = last_eval\n",
    "\n",
    "print(\"Last evaluated configuration, \")\n",
    "print(dehb.vector_to_configspace(config), end=\"\")\n",
    "print(\"got a score of {}, was evaluated at a budget of {:.2f} and \"\n",
    "      \"took {:.3f} seconds to run.\".format(score, budget, cost))\n",
    "print(\"The additional info attached: {}\".format(_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Final model fit with tuned params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[639]\tvalid_0's rmse: 9.60753\n"
     ]
    }
   ],
   "source": [
    "# fit a final model to complete training set and predict submission data\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.01,\n",
    "    'verbosity': -1,\n",
    "    'seed': 0,\n",
    "}\n",
    "\n",
    "bst = lgb.train(\n",
    "    params=params,\n",
    "    num_boost_round=10000,\n",
    "    train_set=lgb_data_eval,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load model\n",
    "# bst.save_model('model.txt')\n",
    "# bst = lgb.Booster(model_file='model.txt')  # init model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
