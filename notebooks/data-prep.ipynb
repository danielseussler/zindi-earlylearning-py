{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Some basic data cleaning and feature pre-processing.\n",
    "\n",
    "In particular, I do: \n",
    "- fix some wrong columns (e.g. gps latitude and longitude values)\n",
    "- remove some indicators of data availability that should have no influence (e.g. gps_ind)\n",
    "- reformat dates\n",
    "- split some columns where multiple languages where provided as a group \n",
    "- throw out variables with to many missings\n",
    "- encode some ordinal categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "import time\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "dataset = pl.read_csv('../data/competition/Train.csv', ignore_errors=True)\n",
    "sbmssn = pl.read_csv('../data/competition/Test.csv', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 679)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>child_id</th><th>data_year</th><th>child_date</th><th>child_age</th><th>child_enrolment_date</th><th>child_months_enrolment</th><th>child_grant</th><th>child_years_in_programme</th><th>child_height</th><th>child_observe_attentive</th><th>child_observe_concentrated</th><th>child_observe_diligent</th><th>child_observe_interested</th><th>child_observe_total</th><th>child_gender</th><th>child_dob</th><th>child_zha</th><th>child_stunted</th><th>child_attends</th><th>child_attendance</th><th>child_languages</th><th>child_age_group</th><th>id_mn_best</th><th>prov_best</th><th>id_dc_best</th><th>dc_best</th><th>mn_best</th><th>ward_best</th><th>id_enumerator</th><th>id_facility</th><th>pqa_date</th><th>pqa_class_age</th><th>pqa_class_age_1</th><th>pqa_class_age_2</th><th>pqa_class_age_3</th><th>pqa_class_age_4</th><th>pqa_class_age_5</th><th>&hellip;</th><th>positionother</th><th>positionotherreason</th><th>sef_ind</th><th>language_match</th><th>elp_ind</th><th>gps_ind</th><th>pre_covid</th><th>ses_proxy</th><th>quintile_used</th><th>id_facility_n</th><th>id_ward_n</th><th>id_mn_n</th><th>id_dc_n</th><th>id_prov_n</th><th>language_assessment_w2</th><th>ses_cat</th><th>obs_lighting_1</th><th>obs_lighting_2</th><th>obs_lighting_3</th><th>obs_lighting_4</th><th>obs_lighting_5</th><th>obs_lighting_6</th><th>obs_lighting_8</th><th>obs_cooking_1</th><th>obs_cooking_2</th><th>obs_cooking_3</th><th>obs_cooking_4</th><th>obs_cooking_5</th><th>obs_cooking_6</th><th>obs_heating_1</th><th>obs_heating_2</th><th>obs_heating_3</th><th>obs_heating_4</th><th>obs_heating_5</th><th>obs_heating_6</th><th>obs_heating_7</th><th>target</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>&hellip;</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;ID_SYSJ2FM0D&quot;</td><td>2022.0</td><td>&quot;2022-02-03&quot;</td><td>59.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Sometimes&quot;</td><td>&quot;Sometimes&quot;</td><td>&quot;Sometimes&quot;</td><td>&quot;Sometimes&quot;</td><td>4.0</td><td>&quot;Female&quot;</td><td>&quot;2017-02-06&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;50-59 months&quot;</td><td>&quot;GT421&quot;</td><td>&quot;GAUTENG&quot;</td><td>&quot;DC42&quot;</td><td>&quot;SEDIBENG&quot;</td><td>&quot;EMFULENI&quot;</td><td>39.0</td><td>20005.0</td><td>761.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>&quot;Yes&quot;</td><td>1.0</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Post COVID&quot;</td><td>2.0</td><td>&quot;Yes&quot;</td><td>7.0</td><td>14.0</td><td>107.0</td><td>134.0</td><td>1051.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>51.5</td></tr><tr><td>&quot;ID_J5BTFOZR3&quot;</td><td>2019.0</td><td>null</td><td>60.163933</td><td>null</td><td>null</td><td>null</td><td>&quot;1st year in th…</td><td>103.0</td><td>&quot;Sometimes&quot;</td><td>&quot;Almost never&quot;</td><td>&quot;Sometimes&quot;</td><td>&quot;Often&quot;</td><td>4.0</td><td>&quot;Female&quot;</td><td>null</td><td>-1.356791</td><td>&quot;Normal&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;60-69 months&quot;</td><td>null</td><td>&quot;KWAZULU-NATAL&quot;</td><td>&quot;DC22&quot;</td><td>&quot;UMGUNGUNDLOVU&quot;</td><td>null</td><td>null</td><td>null</td><td>458.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>&quot;Yes&quot;</td><td>1.0</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Pre-COVID&quot;</td><td>4.0</td><td>&quot;Yes&quot;</td><td>24.0</td><td>null</td><td>null</td><td>367.0</td><td>1832.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>55.869999</td></tr><tr><td>&quot;ID_R00SN7AUD&quot;</td><td>2022.0</td><td>&quot;2022-03-11&quot;</td><td>69.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>108.400002</td><td>&quot;Often&quot;</td><td>&quot;Often&quot;</td><td>&quot;Sometimes&quot;</td><td>&quot;Often&quot;</td><td>7.0</td><td>&quot;Male&quot;</td><td>&quot;2016-05-24&quot;</td><td>-1.250863</td><td>&quot;Normal&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;60-69 months&quot;</td><td>&quot;CPT&quot;</td><td>&quot;WESTERN CAPE&quot;</td><td>&quot;CPT&quot;</td><td>&quot;CITY OF CAPE T…</td><td>&quot;CITY OF CAPE T…</td><td>85.0</td><td>20001.0</td><td>925.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>&quot;No&quot;</td><td>1.0</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Post COVID&quot;</td><td>1.0</td><td>&quot;No&quot;</td><td>8.0</td><td>24.0</td><td>1448.0</td><td>1448.0</td><td>3214.0</td><td>null</td><td>&quot;R0-110&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47.52</td></tr><tr><td>&quot;ID_BSSK60PAZ&quot;</td><td>2021.0</td><td>&quot;2021-10-13&quot;</td><td>53.0</td><td>&quot;2020-01-15&quot;</td><td>20.0</td><td>&quot;No&quot;</td><td>&quot;1st year in th…</td><td>98.099998</td><td>&quot;Almost always&quot;</td><td>&quot;Almost always&quot;</td><td>&quot;Sometimes&quot;</td><td>&quot;Often&quot;</td><td>9.0</td><td>&quot;Male&quot;</td><td>&quot;2017-05-08&quot;</td><td>-1.830364</td><td>&quot;Normal&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;50-59 months&quot;</td><td>&quot;WC025&quot;</td><td>&quot;WESTERN CAPE&quot;</td><td>&quot;DC2&quot;</td><td>&quot;CAPE WINELANDS…</td><td>&quot;BREEDE VALLEY&quot;</td><td>18.0</td><td>2689.0</td><td>308.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>&quot;Yes&quot;</td><td>1.0</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Post COVID&quot;</td><td>3.0</td><td>&quot;No&quot;</td><td>4.0</td><td>22.0</td><td>76.0</td><td>629.0</td><td>3214.0</td><td>null</td><td>&quot;R291-750&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>58.599998</td></tr><tr><td>&quot;ID_IZTY6TC4D&quot;</td><td>2021.0</td><td>&quot;2021-10-13&quot;</td><td>57.0</td><td>&quot;2021-10-13&quot;</td><td>0.0</td><td>null</td><td>&quot;2nd year in pr…</td><td>114.0</td><td>&quot;Almost always&quot;</td><td>&quot;Almost always&quot;</td><td>&quot;Almost always&quot;</td><td>&quot;Almost always&quot;</td><td>12.0</td><td>&quot;Female&quot;</td><td>&quot;2016-12-19&quot;</td><td>1.3292638</td><td>&quot;Normal&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;50-59 months&quot;</td><td>&quot;KZN293&quot;</td><td>&quot;KWAZULU-NATAL&quot;</td><td>&quot;DC29&quot;</td><td>&quot;ILEMBE&quot;</td><td>&quot;NDWEDWE&quot;</td><td>10.0</td><td>542.0</td><td>1749.0</td><td>&quot;2021-10-29&quot;</td><td>&quot;4 5&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&hellip;</td><td>null</td><td>null</td><td>&quot;Yes&quot;</td><td>1.0</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Post COVID&quot;</td><td>1.0</td><td>&quot;No&quot;</td><td>1.0</td><td>30.0</td><td>71.0</td><td>315.0</td><td>1832.0</td><td>null</td><td>&quot;R0-110&quot;</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>76.599998</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 679)\n",
       "┌───────────┬─────────┬──────────┬───────────┬───┬────────────┬────────────┬────────────┬──────────┐\n",
       "│ child_id  ┆ data_ye ┆ child_da ┆ child_age ┆ … ┆ obs_heatin ┆ obs_heatin ┆ obs_heatin ┆ target   │\n",
       "│ ---       ┆ ar      ┆ te       ┆ ---       ┆   ┆ g_5        ┆ g_6        ┆ g_7        ┆ ---      │\n",
       "│ str       ┆ ---     ┆ ---      ┆ f64       ┆   ┆ ---        ┆ ---        ┆ ---        ┆ f64      │\n",
       "│           ┆ f64     ┆ str      ┆           ┆   ┆ f64        ┆ f64        ┆ f64        ┆          │\n",
       "╞═══════════╪═════════╪══════════╪═══════════╪═══╪════════════╪════════════╪════════════╪══════════╡\n",
       "│ ID_SYSJ2F ┆ 2022.0  ┆ 2022-02- ┆ 59.0      ┆ … ┆ null       ┆ null       ┆ null       ┆ 51.5     │\n",
       "│ M0D       ┆         ┆ 03       ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "│ ID_J5BTFO ┆ 2019.0  ┆ null     ┆ 60.163933 ┆ … ┆ null       ┆ null       ┆ null       ┆ 55.86999 │\n",
       "│ ZR3       ┆         ┆          ┆           ┆   ┆            ┆            ┆            ┆ 9        │\n",
       "│ ID_R00SN7 ┆ 2022.0  ┆ 2022-03- ┆ 69.0      ┆ … ┆ null       ┆ null       ┆ null       ┆ 47.52    │\n",
       "│ AUD       ┆         ┆ 11       ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "│ ID_BSSK60 ┆ 2021.0  ┆ 2021-10- ┆ 53.0      ┆ … ┆ null       ┆ null       ┆ null       ┆ 58.59999 │\n",
       "│ PAZ       ┆         ┆ 13       ┆           ┆   ┆            ┆            ┆            ┆ 8        │\n",
       "│ ID_IZTY6T ┆ 2021.0  ┆ 2021-10- ┆ 57.0      ┆ … ┆ 0.0        ┆ 0.0        ┆ 0.0        ┆ 76.59999 │\n",
       "│ C4D       ┆         ┆ 13       ┆           ┆   ┆            ┆            ┆            ┆ 8        │\n",
       "└───────────┴─────────┴──────────┴───────────┴───┴────────────┴────────────┴────────────┴──────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview dataset\n",
    "dataset.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init list of columns to drop - drop at end\n",
    "drop_col = ['child_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode date columns\n",
    "date_col = ['child_date', 'child_enrolment_date', 'child_dob', 'pqa_date', 'pra_date', 'pri_date', 'obs_date']\n",
    "\n",
    "for cn in date_col: \n",
    "    dataset = dataset.with_columns(pl.col(cn).str.strptime(pl.Date, '%Y-%m-%d'))\n",
    "    sbmssn = sbmssn.with_columns(pl.col(cn).str.strptime(pl.Date, '%Y-%m-%d'))\n",
    "\n",
    "for cn in date_col: \n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col(cn).dt.year().alias(cn + '_year').cast(pl.Utf8).cast(pl.Categorical), \n",
    "        pl.col(cn).dt.month().alias(cn + '_month').cast(pl.Utf8).cast(pl.Categorical), \n",
    "        pl.col(cn).dt.quarter().alias(cn + '_quarter').cast(pl.Utf8).cast(pl.Categorical),\n",
    "        pl.col(cn).dt.week().alias(cn + '_week').cast(pl.Utf8).cast(pl.Categorical), \n",
    "        pl.col(cn).cast(pl.Int32)\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col(cn).dt.year().alias(cn + '_year').cast(pl.Utf8).cast(pl.Categorical), \n",
    "        pl.col(cn).dt.month().alias(cn + '_month').cast(pl.Utf8).cast(pl.Categorical), \n",
    "        pl.col(cn).dt.quarter().alias(cn + '_quarter').cast(pl.Utf8).cast(pl.Categorical),\n",
    "        pl.col(cn).dt.week().alias(cn + '_week').cast(pl.Utf8).cast(pl.Categorical), \n",
    "        pl.col(cn).cast(pl.Int32)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Utf8, Utf8, Utf8, Float64]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# geographic groups \n",
    "geo_cat = ['mn_best', 'prov_best', 'dc_best', 'ward_best']\n",
    "geoid_cat = ['id_mn_best', 'id_prov', 'id_dc_best', 'id_ward']\n",
    "\n",
    "dataset.select(pl.col(geo_cat)).dtypes\n",
    "\n",
    "# do this later, don't drop bc not sure if those id_ represent the same info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coded as numerics we should treat them as categories (do later preprocessing with pipelines)\n",
    "numcat_columns = ['id_enumerator', 'id_facility', 'id_team', 'ward_best', 'id_ward'] # FIXME Extension\n",
    "\n",
    "for cn in numcat_columns: \n",
    "    dataset = dataset.with_columns(pl.col(cn).cast(pl.Int64).cast(pl.Utf8).cast(pl.Categorical))\n",
    "    sbmssn = sbmssn.with_columns(pl.col(cn).cast(pl.Int64).cast(pl.Utf8).cast(pl.Categorical))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# copy cells such that we include original and encoded value later\n",
    "encode_col = ['id_enumerator', 'id_facility', 'id_team', 'mn_best', 'prov_best', 'dc_best', 'ward_best', 'id_mn_best', 'id_prov', 'id_dc_best', 'id_ward']\n",
    "\n",
    "for cn in encode_col: \n",
    "    dataset = dataset.with_columns(pl.col(cn).suffix('_enc'))\n",
    "    sbmssn = sbmssn.with_columns(pl.col(cn).suffix('_enc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal encoding for selected categories that may be of substantive interest\n",
    "\n",
    "# child_age_group\n",
    "dict = {'Younger than 50 months': 1, '50-59 months': 2, '60-69 months': 3, '70 Months or older': 4}\n",
    "dataset = dataset.with_columns([\n",
    "    pl.col('child_age_group').map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "    ])\n",
    "sbmssn = sbmssn.with_columns([\n",
    "    pl.col('child_age_group').map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "    ])\n",
    "\n",
    "# \n",
    "process_cols = ['child_observe_attentive', 'child_observe_concentrated', 'child_observe_diligent', 'child_observe_interested']\n",
    "dict = {'Almost never': 1, 'Sometimes': 2, 'Often': 3, 'Almost always': 4}\n",
    "\n",
    "for cn in process_cols:\n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col(cn).map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col(cn).map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "    ])\n",
    "\n",
    "# \n",
    "process_cols = [s + '_ordinal' for s in process_cols] \n",
    "dataset = dataset.with_columns(pl.sum(process_cols).alias('child_observe_score'))\n",
    "sbmssn = sbmssn.with_columns(pl.sum(process_cols).alias('child_observe_score'))\n",
    "\n",
    "# child_years_in_programme\n",
    "dict = {'1st year in the programme': 1, '2nd year in programme': 2, '3rd year in programme': 3}\n",
    "dataset = dataset.with_columns([\n",
    "    pl.col('child_years_in_programme').map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "    ])\n",
    "sbmssn = sbmssn.with_columns([\n",
    "    pl.col('child_years_in_programme').map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "    ])\n",
    "\n",
    "# \n",
    "process_cols = ['pra_free_play', 'pra_free_play_outdoor']\n",
    "dict = {'None': 1, '30 minutes or less': 2, 'Up to 1 hour': 3, 'Up to 2 hours': 4, 'More than 3 hours': 5}\n",
    "\n",
    "for cn in process_cols:\n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col(cn).map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col(cn).map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "    ])\n",
    "\n",
    "#\n",
    "dict = {'Seldom': 1, 'Sometime': 2, 'Often': 3}\n",
    "dataset = dataset.with_columns([\n",
    "    pl.col('pra_engaged').map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "])\n",
    "\n",
    "sbmssn = sbmssn.with_columns([\n",
    "    pl.col('pra_engaged').map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "])\n",
    "\n",
    "#\n",
    "dict = {'R0': 1, 'Less than R500 per month': 2, 'R500 – R749': 3, 'R750 – R999': 4, 'R1000 – R1249': 5, \n",
    "        'R1500 – R1999': 6, 'R2500 – R2999': 7, ' R3000 – R3499': 7, 'R3500 – R3999': 8, 'R4000 – R4449': 9, \n",
    "        'R 5000 – R5999': 10, 'More than R6000': 11}\n",
    "dataset = dataset.with_columns([\n",
    "    pl.col('pra_salary').map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "])\n",
    "\n",
    "sbmssn = sbmssn.with_columns([\n",
    "    pl.col('pra_salary').map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "])\n",
    "\n",
    "#\n",
    "dict = {'Other': 1, 'Below Grade 12/matric': 2, 'Certificate': 3, 'Matric/National Senior Certificate': 4, 'R1000 – R1249': 5, \n",
    "        'Diploma': 6, 'Undergraduate Degree': 7, ' Postgraduate degree': 7}\n",
    "dataset = dataset.with_columns([\n",
    "    pl.col('pra_education').map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "])\n",
    "\n",
    "sbmssn = sbmssn.with_columns([\n",
    "    pl.col('pra_education').map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "])\n",
    "\n",
    "#\n",
    "dict = {'Once a week': 1, 'Two times a week': 2, 'Three times a week': 3, 'Four times a week': 4, 'Five times a week': 5}\n",
    "dataset = dataset.with_columns([\n",
    "    pl.col('pri_attendance').map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "])\n",
    "\n",
    "sbmssn = sbmssn.with_columns([\n",
    "    pl.col('pri_attendance').map_dict(dict, default=None, return_dtype=pl.Int64).suffix('_ordinal')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English + isiZulu +', 'Afrikaans', 'English + isiNdebele +', 'English + Afrikaans +', 'English + isiXhosa +', 'isiZulu', 'Setswana', 'Sesotho se Leboa (Sepedi)', 'isiZulu + isiXhosa +', 'English + Xitsonga +', 'isiXhosa + Xitsonga +', None, 'English + Sesotho se Leboa (Sepedi) +', 'Tshivenda', 'English + Setswana +', 'Sesotho', 'isiXhosa', 'Afrikaans + Setswana +', 'English + isiZulu + isiXhosa', 'English']\n"
     ]
    }
   ],
   "source": [
    "print(dataset['child_languages'].unique().to_list(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract child languages here\n",
    "child_langs = ['Afrikaans', 'English', 'isiNdebele', 'isiXhosa',\n",
    "               'isiZulu', 'Xitsonga', 'Setswana', 'Sesotho', 'Sepedi']\n",
    "\n",
    "for ln in child_langs:\n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col('child_languages').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'child_languages_{ln}')\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col('child_languages').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'child_languages_{ln}')\n",
    "    ])\n",
    "\n",
    "drop_col.append('child_languages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME count languages a child speaks\n",
    "dataset = dataset.with_columns([\n",
    "    pl.sum(\n",
    "        pl.col('^child_languages.*$').\n",
    "        cast(pl.Utf8).\n",
    "        str.contains('Yes').\n",
    "        cast(pl.Int32)\n",
    "    ).alias('child_languages_count')\n",
    "])\n",
    "\n",
    "sbmssn = sbmssn.with_columns([\n",
    "    pl.sum(\n",
    "        pl.col('^child_languages.*$').\n",
    "        cast(pl.Utf8).\n",
    "        str.contains('Yes').\n",
    "        cast(pl.Int32)\n",
    "    ).alias('child_languages_count')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English + Afrikaans +', 'Sesotho', 'isiXhosa', 'English', 'English + isiZulu +', 'isiZulu', None, 'Afrikaans', 'English + Afrikaans + isiXhosa', 'Setswana', 'Afrikaans + isiZulu +', 'English + isiXhosa +']\n"
     ]
    }
   ],
   "source": [
    "print(dataset['pri_languages'].unique().to_list(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pri_languages here\n",
    "pri_langs = ['Afrikaans', 'English', 'isiXhosa', 'isiZulu', 'Setswana', 'Sesotho']\n",
    "\n",
    "for ln in pri_langs:\n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col('pri_languages').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_languages_{ln}')\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col('pri_languages').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_languages_{ln}')\n",
    "    ])\n",
    "\n",
    "drop_col.append('pri_languages')\n",
    "\n",
    "# Convert this to categorical\n",
    "dataset = dataset.with_columns([\n",
    "    pl.col('language_match').map_dict({0: 'No', 1: 'Yes'}, default=None).cast(pl.Categorical)\n",
    "])\n",
    "\n",
    "sbmssn = sbmssn.with_columns([\n",
    "    pl.col('language_match').map_dict({0: 'No', 1: 'Yes'}, default=None).cast(pl.Categorical)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the gps column\n",
    "dataset = dataset.with_columns(\n",
    "    pl.col('gps').str.split(' ').\\\n",
    "    arr.to_struct(n_field_strategy='max_width').\\\n",
    "    struct.rename_fields(['gps_lat', 'gps_lon'])).\\\n",
    "    unnest('gps')\n",
    "\n",
    "sbmssn = sbmssn.with_columns(\n",
    "    pl.col('gps').str.split(' ').\\\n",
    "    arr.to_struct(n_field_strategy='max_width').\\\n",
    "    struct.rename_fields(['gps_lat', 'gps_lon'])).\\\n",
    "    unnest('gps')\n",
    "\n",
    "# cast to numeric\n",
    "for cn in ['gps_lat', 'gps_lon']:\n",
    "    dataset = dataset.with_columns(pl.col(cn).cast(pl.Float64))\n",
    "    sbmssn = sbmssn.with_columns(pl.col(cn).cast(pl.Float64))\n",
    "\n",
    "drop_col.append('gps_ind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some strings should be encoded as NA (probably not exhaustive)\n",
    "dataset = dataset.with_columns([\n",
    "    pl.when(pl.col(pl.Utf8).str.contains('Do Not Know|Missing|Don\\'t know|Refuse|DON\\'T KNOW|DON\\'T KNOW.|DON\\'T KNOW THE REASON FOR CONDITIONAL'))\n",
    "    .then(None)\n",
    "    .otherwise(pl.col(pl.Utf8))\n",
    "    .keep_name()\n",
    "])\n",
    "\n",
    "sbmssn = sbmssn.with_columns([\n",
    "    pl.when(pl.col(pl.Utf8).str.contains('Do Not Know|Missing|Don\\'t know|Refuse|DON\\'T KNOW|DON\\'T KNOW.|DON\\'T KNOW THE REASON FOR CONDITIONAL'))\n",
    "    .then(None)\n",
    "    .otherwise(pl.col(pl.Utf8))\n",
    "    .keep_name()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column pri_network_type has different data types between the two data frames.\n",
      "Column pri_staff_changes_reasons has different data types between the two data frames.\n",
      "Column pri_food_donor has different data types between the two data frames.\n"
     ]
    }
   ],
   "source": [
    "# check where dataset and sbmssn diasgree on data types\n",
    "for cn in dataset.select(pl.exclude('target')).columns:\n",
    "    if dataset[cn].dtype != sbmssn[cn].dtype:\n",
    "        print(f'Column {cn} has different data types between the two data frames.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix those columns\n",
    "for answer in [1, 2, 3, 97]:\n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col('pri_network_type').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_network_type_{answer}')\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col('pri_network_type').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_network_type_{answer}')\n",
    "    ])\n",
    "\n",
    "for answer in [1, 2, 3, 4, 5, 6, 97]:\n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col('pri_staff_changes_reasons').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_staff_changes_reasons_{answer}')\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col('pri_staff_changes_reasons').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_staff_changes_reasons_{answer}')\n",
    "    ])\n",
    "\n",
    "for answer in [1, 2, 3, 4, 97]:\n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col('pri_food_donor').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_food_donor_{answer}')\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col('pri_food_donor').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'pri_food_donor_{answer}')\n",
    "    ])\n",
    "\n",
    "# drop the splitted columns\n",
    "drop_col.extend(['pri_network_type', 'pri_staff_changes_reasons', 'pri_food_donor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical encoding of some other survey responses\n",
    "for answer in [1, 2, 3, 4, 5, 97]:\n",
    "    dataset = dataset.with_columns([\n",
    "        pl.col('health').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'health_{answer}')\n",
    "    ])\n",
    "\n",
    "    sbmssn = sbmssn.with_columns([\n",
    "        pl.col('health').\n",
    "        str.contains(ln).\n",
    "        map_dict({0: 'No', 1: 'Yes'}, default=None).\n",
    "        cast(pl.Categorical).\n",
    "        alias(f'health_{answer}')\n",
    "    ])\n",
    "\n",
    "# drop the splitted columns\n",
    "drop_col.append('health')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories that are encoded yes / no convert to 1 / 0 \n",
    "# FIXME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the column names ordered by the least NAs they have\n",
    "# the more missing, the less it is going to contribute to the model\n",
    "threshold_missings = 6000 # FIXME\n",
    "exclude_by_na = dataset.to_pandas().isna().sum().sort_values(ascending=True).where(lambda x : x > threshold_missings).dropna()\n",
    "drop_col.extend(exclude_by_na.index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col.extend(['obs_materials', 'obs_handwashing', 'obs_area', 'obs_toilet',\n",
    "    'obs_equipment', 'obs_safety', 'obs_hazard', 'pqa_class_age',\n",
    "    'pra_groupings', 'pra_plans', 'obs_access_disability', 'pra_cohort',\n",
    "    'pra_plan_4yrs', 'pra_plan_5yrs', 'pra_plan_4yrsother', 'pra_plan_5yrsother',\n",
    "    'pra_qualification', 'pra_ncf_trainer', 'pra_training', 'pri_language',\n",
    "    'pri_meal', 'pri_money',  'pri_funding_salary', 'pri_expenseother',\n",
    "    'pri_clinic_travel', 'pri_covid_awareness', 'pri_covid_precautions',\n",
    "    'pri_food_type', 'pri_records', 'pri_support_provider', \n",
    "    'pri_qualification', 'pri_email_network_forum', \n",
    "    'pri_reason_register_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "dataset = dataset.select(pl.all().exclude(drop_col))\n",
    "sbmssn = sbmssn.select(pl.all().exclude(list(set(drop_col) - set(['child_id']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other strings to categories\n",
    "for cn in dataset.select(pl.col(pl.Utf8)).columns: \n",
    "    dataset = dataset.with_columns(pl.col(cn).cast(pl.Categorical))\n",
    "    sbmssn = sbmssn.with_columns(pl.col(cn).cast(pl.Categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Float64: 68, Int32: 3, Categorical: 204, Int64: 15}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary stats\n",
    "dataset.shape\n",
    "types = dataset.dtypes\n",
    "{x:types.count(x) for x in types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as parquet for use in tuning and prediction\n",
    "dataset.write_parquet(\"../data/clean/dataset.parquet\")\n",
    "sbmssn.write_parquet(\"../data/clean/sbmssn.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
