{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Hyper-parameter tuning with Hyperband informed by Hyperband.\n",
    "\n",
    "L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, and A. Talwalkar, ‘Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization’. arXiv, Jun. 18, 2018. Accessed: Apr. 22, 2023. [Online]. Available: http://arxiv.org/abs/1603.06560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "import time\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of brackets 5\n"
     ]
    }
   ],
   "source": [
    "R = 5000/50\n",
    "num_brackets = math.floor(math.log(R, 3)) + 1\n",
    "print('Number of brackets', num_brackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna hyper-parameter optimization with hyperband\n",
    "num_boost_round = 5000\n",
    "\n",
    "lgb_data_eval = lgb.Dataset(\n",
    "    data=eval_data_x, label=eval_data_y, free_raw_data=False)\n",
    "lgb_data_valid = lgb.Dataset(\n",
    "    data=valid_data_x, label=valid_data_y, reference=lgb_data_eval, free_raw_data=False)\n",
    "lgb_data_test = lgb.Dataset(\n",
    "    data=test_data_x, label=test_data_y, reference=lgb_data_eval)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.01,\n",
    "        # 'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-4, 100.0),\n",
    "        # 'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-4, 100.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 16, 512, log=True),\n",
    "        # 'feature_fraction': trial.suggest_uniform('feature_fraction', 0.6, 1.0),\n",
    "        # 'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.6, 1.0),\n",
    "        'cat_l2': trial.suggest_uniform('cat_l2', 5, 15),\n",
    "        'cat_smooth': trial.suggest_uniform('cat_smooth', 5, 15),\n",
    "        'verbosity': -1,\n",
    "        'seed': 0\n",
    "    }\n",
    "\n",
    "    # init model and pruning mechanism\n",
    "    gbm = lgb.train(\n",
    "        params=params,\n",
    "        num_boost_round=50,\n",
    "        train_set=lgb_data_eval,\n",
    "        valid_sets=[lgb_data_valid],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)],\n",
    "        keep_training_booster=True\n",
    "    )\n",
    "\n",
    "    for step in range(num_boost_round):\n",
    "        gbm = lgb.train(\n",
    "            params=params,\n",
    "            num_boost_round=num_boost_round,\n",
    "            train_set=lgb_data_eval,\n",
    "            valid_sets=[lgb_data_valid],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)],\n",
    "            keep_training_booster=True,\n",
    "            init_model=gbm\n",
    "        )\n",
    "\n",
    "        intermediate_pred = gbm.predict(\n",
    "            data=valid_data_x, num_iteration=gbm.best_iteration)\n",
    "        intermediate_rmse = mean_squared_error(\n",
    "            valid_data_y, intermediate_pred, squared=False)\n",
    "        \n",
    "        trial.report(intermediate_rmse, step)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    valid_data_pred = gbm.predict(\n",
    "        data=valid_data_x, num_iteration=gbm.best_iteration)\n",
    "    rmse = mean_squared_error(valid_data_y, valid_data_pred, squared=False)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "pruner = optuna.pruners.HyperbandPruner(\n",
    "    min_resource=50, max_resource=num_boost_round, reduction_factor=3)\n",
    "\n",
    "study_hb = optuna.create_study(\n",
    "    sampler=sampler, pruner=pruner, direction='minimize')\n",
    "study_hb.optimize(objective, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "print('Number of finished trials:', len(study_hb.trials))\n",
    "print('Best trial:', study_hb.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_optimization_history(study_hb)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_intermediate_values(study_hb)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_contour(study_hb)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
