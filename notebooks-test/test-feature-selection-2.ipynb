{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Feature selection with univariate boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "import category_encoders as ce\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "from feature_engine.encoding import MeanEncoder\n",
    "from feature_engine.selection import SelectBySingleFeaturePerformance\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This does not work great with categorical variables. Let's try target encoding for cardinality higher than 10, the rest is one-hot encoded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8585, 290)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "dataset = pl.read_parquet(\"../data/clean/dataset.parquet\")\n",
    "sbmssn = pl.read_parquet(\"../data/clean/sbmssn.parquet\")\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to pandas\n",
    "dataset_x = dataset.drop(['target']).to_pandas()\n",
    "dataset_y = dataset.get_column('target').to_pandas()\n",
    "newdata = sbmssn.drop('child_id').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['child_grant', 'child_years_in_programme', 'child_observe_attentive',\n",
       "       'child_observe_concentrated', 'child_observe_diligent',\n",
       "       'child_observe_interested', 'child_gender', 'child_stunted',\n",
       "       'child_age_group', 'id_mn_best',\n",
       "       ...\n",
       "       'phase_natemis', 'language_child', 'language_assessment',\n",
       "       'facility_type', 'sef_ind', 'language_match', 'elp_ind', 'pre_covid',\n",
       "       'quintile_used', 'ses_cat'],\n",
       "      dtype='object', length=192)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x.select_dtypes(include=\"category\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_cardinality_features(df, cardinality=5):\n",
    "    \"\"\"\n",
    "    Returns a list of column names of categorical features with cardinality higher than a given threshold.\n",
    "    \"\"\"\n",
    "    return [col for col in df.select_dtypes(include=\"category\").columns if df[col].nunique() > cardinality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train-valid-test set\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=1 - train_ratio, random_state=0)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical features\n",
    "num_features = dataset_x.select_dtypes(exclude=\"category\").columns\n",
    "cat_features = list(dataset_x.select_dtypes(include=\"category\").columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfp = SelectBySingleFeaturePerformance(\n",
    "    estimator=lgb.LGBMRegressor(random_state=0),\n",
    "    scoring='explained_variance',\n",
    "    threshold=0.005,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "x_train = sfp.fit_transform(x_train, y_train)\n",
    "x_val = sfp.transform(x_val)\n",
    "x_test = sfp.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_year                           float64\n",
       "child_date                          float64\n",
       "child_age                           float64\n",
       "child_enrolment_date                float64\n",
       "child_months_enrolment              float64\n",
       "                                     ...   \n",
       "child_years_in_programme_ordinal    float64\n",
       "pra_free_play_ordinal               float64\n",
       "pra_free_play_outdoor_ordinal       float64\n",
       "pra_engaged_ordinal                 float64\n",
       "pri_attendance_ordinal              float64\n",
       "Length: 287, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lightgbm data format\n",
    "lgb_train = lgb.Dataset(data=x_train, label=y_train)\n",
    "lgb_val = lgb.Dataset(data=x_val, label=y_val, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train vanilla lightgbm model\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.005,\n",
    "    'num_leaves': 32,\n",
    "    'feature_fraction': 1,\n",
    "    'bagging_fraction': 1,\n",
    "    'cat_l2': 10,\n",
    "    'cat_smooth': 10,\n",
    "    'verbosity': -1,\n",
    "    'seed': 0\n",
    "}\n",
    "\n",
    "bst = lgb.train(\n",
    "    params=params,\n",
    "    num_boost_round=5000,\n",
    "    train_set=lgb_train,\n",
    "    valid_sets=lgb_val, \n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=5, verbose=False)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1381"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.current_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.50782344212471"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create final predictions\n",
    "y_test_pred = bst.predict(x_test)\n",
    "mean_squared_error(y_test_pred, y_test, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain final model\n",
    "explainer = shap.TreeExplainer(bst)\n",
    "shap_values = explainer.shap_values(dataset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = {\n",
    "    'feature_1': [], 'feature_2': [], 'feature_3': [], 'feature_4': [], 'feature_5': [], 'feature_6': [], 'feature_7': [],\n",
    "    'feature_8': [], 'feature_9': [], 'feature_10': [], 'feature_11': [], 'feature_12': [], 'feature_13': [], 'feature_14': [],\n",
    "    'feature_15': []\n",
    "}\n",
    "\n",
    "shap_values = explainer.shap_values(df_to_predict)\n",
    "\n",
    "for sv in shap_values: \n",
    "    arr = np.argsort(sv)[::-1][:15]\n",
    "    for ind, a in enumerate(arr):\n",
    "        place = f'feature_{ind+1}'\n",
    "        ft[place].append(df_to_predict.columns[a])\n",
    "\n",
    "final_sub = sbmssn.select('child_id')\n",
    "final_sub = final_sub.with_columns(pl.Series(sbmssn_pred).alias('target'))\n",
    "\n",
    "ft = pl.DataFrame(ft)\n",
    "final_sub = pl.concat([final_sub, ft], how='horizontal')\n",
    "\n",
    "fname = '../submission/' + time.strftime(\"%Y%m%d-%H%M%S\") + '.csv'\n",
    "final_sub.write_csv(fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
